{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision.models import vgg19\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import glob\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 2000 # Define number of samples to use for training\n",
    "\n",
    "# Normalization parameters for pre-trained PyTorch models\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def denormalize(tensors):\n",
    "    \"\"\" Denormalizes image tensors using mean and std \"\"\"\n",
    "    for c in range(3):\n",
    "        tensors[:, c].mul_(std[c]).add_(mean[c])\n",
    "    return torch.clamp(tensors, 0, 255)\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, hr_shape):\n",
    "        hr_height, hr_width = hr_shape\n",
    "        # Transforms for low resolution images and high resolution images\n",
    "        self.lr_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    (hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "        self.hr_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.files = list(sorted(glob.glob(root + \"/*.*\")))[0:SAMPLES]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img_lr = self.lr_transform(img)\n",
    "        img_hr = self.hr_transform(img)\n",
    "\n",
    "        return {\"lr\": img_lr, \"hr\": img_hr}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.vgg19_54 = nn.Sequential(*list(vgg19_model.features.children())[:35])\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.vgg19_54(img)\n",
    "\n",
    "\n",
    "class DenseResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(DenseResidualBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "        def block(in_features, non_linearity=True):\n",
    "            layers = [nn.Conv2d(in_features, filters, 3, 1, 1, bias=True)]\n",
    "            if non_linearity:\n",
    "                layers += [nn.LeakyReLU()]\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.b1 = block(in_features=1 * filters)\n",
    "        self.b2 = block(in_features=2 * filters)\n",
    "        self.b3 = block(in_features=3 * filters)\n",
    "        self.b4 = block(in_features=4 * filters)\n",
    "        self.b5 = block(in_features=5 * filters, non_linearity=False)\n",
    "        self.blocks = [self.b1, self.b2, self.b3, self.b4, self.b5]\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(inputs)\n",
    "            inputs = torch.cat([inputs, out], 1)\n",
    "        return out.mul(self.res_scale) + x\n",
    "\n",
    "\n",
    "class ResidualInResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(ResidualInResidualDenseBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.dense_blocks = nn.Sequential(\n",
    "            DenseResidualBlock(filters), DenseResidualBlock(filters), DenseResidualBlock(filters)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense_blocks(x).mul(self.res_scale) + x\n",
    "\n",
    "\n",
    "class GeneratorRRDB(nn.Module):\n",
    "    def __init__(self, channels, filters=64, num_res_blocks=16, num_upsample=2):\n",
    "        super(GeneratorRRDB, self).__init__()\n",
    "\n",
    "        # First layer\n",
    "        self.conv1 = nn.Conv2d(channels, filters, kernel_size=3, stride=1, padding=1)\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks)])\n",
    "        # Second conv layer post residual blocks\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1)\n",
    "        # Upsampling layers\n",
    "        upsample_layers = []\n",
    "        for _ in range(num_upsample):\n",
    "            upsample_layers += [\n",
    "                nn.Conv2d(filters, filters * 4, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.PixelShuffle(upscale_factor=2),\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsample_layers)\n",
    "        # Final output block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filters, channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.res_blocks(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        in_channels, in_height, in_width = self.input_shape\n",
    "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n",
    "        self.output_shape = (1, patch_h, patch_w)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, first_block=False):\n",
    "            layers = []\n",
    "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
    "            if not first_block:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = in_channels\n",
    "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def denormalize(tensors):\n",
    "    \"\"\" Denormalizes image tensors using mean and std \"\"\"\n",
    "    for c in range(3):\n",
    "        tensors[:, c].mul_(std[c]).add_(mean[c])\n",
    "    return torch.clamp(tensors, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PY\\lib\\site-packages\\torchvision\\transforms\\transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"images/training\", exist_ok=True)\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "hr_height = 256 # high res. image height\n",
    "hr_width = 265 # high res. image width\n",
    "channels = 3 # number of image channels\n",
    "residual_blocks = 23 # number of residual blocks in the generator\n",
    "epoch = 0 # epoch to start training from\n",
    "lr = 0.0002 # learning rate\n",
    "b1 = 0.9 # adam: decay of first order momentum of gradient\n",
    "b2 = 0.999 # adam: decay of first order momentum of gradient\n",
    "dataset_name = \"img_align_celeba\"\n",
    "n_cpu = 8 # number of cpu threads to use during batch generation\n",
    "n_epochs = 20 # number of epochs of training\n",
    "batch_size = 4 # size of the batches\n",
    "lambda_adv = 5e-3 # adversarial loss weight\n",
    "lambda_pixel = 1e-2 # pixel-wise loss weight\n",
    "warmup_batches = 500 # number of batches with pixel-wise loss only\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hr_shape = (hr_height, hr_width)\n",
    "# Initialize generator and discriminator\n",
    "generator = GeneratorRRDB(channels, filters=64,\n",
    "                          num_res_blocks=residual_blocks).to(device)\n",
    "discriminator = Discriminator(\n",
    "    input_shape=(channels, *hr_shape)).to(device)\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "# Set feature extractor to inference mode\n",
    "feature_extractor.eval()\n",
    "# Losses\n",
    "criterion_GAN = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "criterion_content = torch.nn.L1Loss().to(device)\n",
    "criterion_pixel = torch.nn.L1Loss().to(device)\n",
    "if epoch != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(\n",
    "        \"saved_models/generator_%d.pth\" % epoch))\n",
    "    discriminator.load_state_dict(torch.load(\n",
    "        \"saved_models/discriminator_%d.pth\" % epoch))\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(\"../../src/data/%s\" % dataset_name, hr_shape=hr_shape),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu,\n",
    ")\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "for epoch in range(epoch, n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        # Configure model input\n",
    "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
    "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(\n",
    "            np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(\n",
    "            np.zeros((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        # Generate a high resolution image from low resolution input\n",
    "        gen_hr = generator(imgs_lr)\n",
    "        # Measure pixel-wise loss against ground truth\n",
    "        loss_pixel = criterion_pixel(gen_hr, imgs_hr)\n",
    "        if batches_done < warmup_batches:\n",
    "            # Warm-up (pixel-wise loss only)\n",
    "            loss_pixel.backward()\n",
    "            optimizer_G.step()\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [G pixel: %f]\"\n",
    "                % (epoch, opt.n_epochs, i, len(dataloader), loss_pixel.item())\n",
    "            )\n",
    "            continue\n",
    "        # Extract validity predictions from discriminator\n",
    "        pred_real = discriminator(imgs_hr).detach()\n",
    "        pred_fake = discriminator(gen_hr)\n",
    "        # Adversarial loss (relativistic average GAN)\n",
    "        loss_GAN = criterion_GAN(\n",
    "            pred_fake - pred_real.mean(0, keepdim=True), valid)\n",
    "        # Content loss\n",
    "        gen_features = feature_extractor(gen_hr)\n",
    "        real_features = feature_extractor(imgs_hr).detach()\n",
    "        loss_content = criterion_content(gen_features, real_features)\n",
    "        # Total generator loss\n",
    "        loss_G = loss_content + lambda_adv * \\\n",
    "            loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        pred_real = discriminator(imgs_hr)\n",
    "        pred_fake = discriminator(gen_hr.detach())\n",
    "        # Adversarial loss for real and fake images (relativistic average GAN)\n",
    "        loss_real = criterion_GAN(\n",
    "            pred_real - pred_fake.mean(0, keepdim=True), valid)\n",
    "        loss_fake = criterion_GAN(\n",
    "            pred_fake - pred_real.mean(0, keepdim=True), fake)\n",
    "        # Total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, content: %f, adv: %f, pixel: %f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                n_epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                loss_content.item(),\n",
    "                loss_GAN.item(),\n",
    "                loss_pixel.item(),\n",
    "            )\n",
    "        )\n",
    "        if(batches_done % 10 == 0):\n",
    "            # Save image grid with upsampled inputs and ESRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "            img_grid = denormalize(torch.cat((imgs_lr, gen_hr), -1))\n",
    "            save_image(img_grid, \"images/training/%d.png\" %\n",
    "                       batches_done, nrow=1, normalize=False)\n",
    "            # Save model checkpoints\n",
    "            torch.save(generator.state_dict(),\n",
    "                       \"saved_models/generator_%d.pth\" % epoch)\n",
    "            torch.save(discriminator.state_dict(),\n",
    "                       \"saved_models/discriminator_%d.pth\" % epoch)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "404cc3ada02fe0162fc446d61bd19c97c4694fd6aade534950fa86161cee10cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
